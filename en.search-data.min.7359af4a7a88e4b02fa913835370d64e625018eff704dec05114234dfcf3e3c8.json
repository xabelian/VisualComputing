[{"id":0,"href":"/VisualComputing/docs/Coreccion-de-color-para-Daltonismo/Modificacion-de-imagenes-para-personas-con-dificultades-en-la-percepcion-de-Color/","title":"Modificacion De Imagenes Para Personas Con Dificultades en La Percepcion De Color","section":"Docs","content":"Modificación de imagenes para personas con dificultades en la percepcion de color #  Introducción #  El daltonismo es la incapacidad para ver algunos colores en la forma normal.\nEste ocurre cuando hay un problema con los pigmentos en ciertas células nerviosas del ojo que perciben el color. Estas células se llaman conos y se encuentran en la capa de tejido sensible a la luz que recubre la parte posterior del ojo, llamada la retina.\nSi sólo falta un pigmento, usted puede tener dificultad para diferenciar entre el rojo y el verde, que es el tipo más común de daltonismo. Si falta un pigmento diferente, usted puede tener dificultad para ver los colores azul y amarillo. Las personas con daltonismo para los colores azul y amarillo con frecuencia tienen problemas para identificar también los colores rojos y verdes.\nLa forma más grave de daltonismo es la acromatopsia. Se trata de una rara afección en la cual una persona no puede ver ningún color, solamente sombras de gris.\nLa mayoría de los casos de daltonismo se deben a un problema genético. Muy pocas mujeres son daltónicas y aproximadamente 1 de cada 10 hombres sufren alguna forma de daltonismo.\nTipos de Daltonismo #    Acromático: no hay percepción de ningún color, la visión es en blanco y negro con matices de gris. Es poco frecuente (1/100.000).\n  Monocromático: solo se ve un color, en distintas tonalidades.\n  Dicromático: existen tres tipos:\n Protanopía, ausencia de fotoreceptores al rojo. La parte del espectro de colores que normalmente se ve rojo-verde, se ve gris. Deuteranopía, ausencia de fotoreceptores al verde. La parte del espectro de colores que normalmente se ve verde, se ve gris. Tritanopía, ausencia de fotoreceptores al azul, esta es una condición muy rara.    Tricromático anómalo: el portador confunde los colores, y es la alteración que se presenta con más frecuencia. En la macula existen los tres tipos de fotoreceptores (para rojo, verde y azul) pero la captación de colores es irregular. Estos pacientes tienen percepción de los colores anormal, semejante a los dicromáticos pero menos acentuadas, dentro de este grupo se incluyen:\n Protanomalía (1% en hombres- 0.01 % en mujeres). Deuteranomalía es la más frecuente, (6% en hombres- 0.4% en mujeres). Tritanomalía la menos frecuente (0.01 en hombres- 0.01 % en mujeres).    Entendiendo el problema #  Para las personas que no tenemos dificultades para el reconocimiento de colores, entender el daltonismo muchas veces es simplemente creer que se confunde un color por otro y ya, pero esta condición, como pudimos ver anteriormente, tiene distintas variantes y no solo eso, tambien niveles. Una persona con daltonismo tricromático con deutoranopia en grado leve moderado, podria percibir los colores rojos de una forma no tan vívida\nSi mediante al procesamiento de imagenes queremos simular este tipo de daltonismo, lo primero que debemos recordar es que en una imagen el color de cada pixel esta compuesto por niveles de cada uno de los colores RGB.\nEntonces si dismunuimos el nivel del rojo y aumentamos el nivel del verde podriamos acercarnos a una recreación de este tipo de daltonismo\nDeteccion de Daltonismo #  Existen diferentes formas para la detección del Daltonismo.\nTests de Ishihara #  Este es el tipo más común de prueba de daltonismo. Un oftalmólogo (usualmente) le pedirá que mire una imagen formada por puntos de colores con un número o forma de diferente color en el medio. Si la forma se mezcla con el fondo y no puedes verla, es posible que el paciente tenga un tipo de daltonismo.\nDiferentes placas de color pueden verificar diferentes tipos de daltonismo.\nTest con Anomaloscopio #  Esta prueba verifica si el paciente puede igualar el brillo de dos luces. Se mira a través de un ocular a 2 luces que tienen diferentes niveles de brillo. Se usan perillas para ajustar las luces y se trata de hacer que coincidan. Si no puede igualar el brillo de las 2 luces, es posible que el paciente sufra de daltonismo.\nTest de tonos #  En una prueba de tono, Se entregan bloques de diferentes colores. Su oftalmólogo pide al paciente que las coloque en el orden del arcoíris, como de rojo a púrpura. Si tiene problemas para ponerlos en el orden correcto, es posible que tenga un tipo de daltonismo. Los oftalmólogos a menudo usan esta prueba para las personas que necesitan tener una visión del color muy precisa para sus trabajos, como fotógrafos o diseñadores.\nResultados #  Simulando la vision de un paciente #  Original Image with red predominance #  Load Image let img;  function setup() {  createCanvas(600, 505);  img = loadImage(\u0026#39;/VisualComputing/sketches/red_crayons.png\u0026#39;); }  function draw() {  image(img, 0, 0); }            let img; function setup() { createCanvas(600, 505); img = loadImage(\u0026#39;/VisualComputing/sketches/red_crayons.png\u0026#39;); } function draw() { image(img, 0, 0); }      \"  Modify Red to Green  let img;  function preload() {  img = loadImage(\u0026#39;/VisualComputing/sketches/red_crayons.png\u0026#39;); }  function setup() {  createCanvas(600, 505);   img.loadPixels();  // Se recorre cada pixel de la imagen  for (let y = 0; y \u0026lt; img.height; y++) {  for (let x = 0; x \u0026lt; img.width; x++) {  // Lee el color de cada pixel  let originalColor = img.get(x, y);   // Modifica los colores rojo y verde. El azul permanece intacto  const r = red(originalColor)-50;  const g = green(originalColor)+50;  const b = blue(originalColor);  let outputColor = color(r, g, b);   // Coloca el nuevo color a cada pixel  img.set(x, y, outputColor);  }  }  img.updatePixels(); }  function draw() {  image(img, 0, 0); }            let img; function preload() { img = loadImage(\u0026#39;/VisualComputing/sketches/red_crayons.png\u0026#39;); } function setup() { createCanvas(600, 505); img.loadPixels(); // Se recorre cada pixel de la imagen for (let y = 0; y \u0026lt; img.height; y\u0026#43;\u0026#43;) { for (let x = 0; x \u0026lt; img.width; x\u0026#43;\u0026#43;) { // Read the pixel\u0026#39;s color let originalColor = img.get(x, y); // Inverse the color const r = red(originalColor)-50; const g = green(originalColor)\u0026#43;50; const b = blue(originalColor); let outputColor = color(r, g, b); // Set the pixel\u0026#39;s color img.set(x, y, outputColor); } } img.updatePixels(); } function draw() { image(img, 0, 0); }      \"  Mejorando la visibilidad por medio de p5 #  Se uso Coblis con la siguiente imagen para simular la vision de un paciente con Deuteranopia (ausencia de la percepción del espectro del color verde).\nA la izquierda la imagen original, a la derecha la imagen como la veria un paciente con Deuteranopia al ser simulado con Coblis.\nLa modificación de los valores de RGB permite aumentar el contraste de la imagen y diferencias las colores.\nModifying colors for visibility   let img;  function preload() {  img = loadImage(\u0026#39;https://xabelian.github.io/VisualComputing/sketches/original.jpg\u0026#39;);  }   function setup() {  createCanvas(404, 402);  image(img, 0, 0, width, height);  let d = pixelDensity();  loadPixels();  for (var y = 0; y \u0026lt; height*4; y++) {  for (var x = 0; x \u0026lt; width; x++) {  var index = (x + y * width)*4;  var r = pixels[index+0];  var g = pixels[index+1];  var b = pixels[index+2];  var a = pixels[index+3];   if (g \u0026gt; 80){  pixels[index+2] = b+70  //pixels[index+1] = g-40  }    }  }  updatePixels();  }                \"  Con este resultado, nuevamente simulamos usando Coblis y se obtiene la siguiente imagen.\nReferencias #  How to make figures and presentations that are friendly to Colorblind people Understanding the concept of channels in an image\n"},{"id":1,"href":"/VisualComputing/docs/Coreccion-de-color-para-Daltonismo/Rasterizaci%C3%B3n-Y-Scene-Trees/","title":"Rasterización Y Scene Trees","section":"Docs","content":"Rasterización Y Scene Trees #  Rasterizacion #  Scene Trees #  3D Brush #  p5 iFrame ShortCode \u0026lt; p5-iframe sketch=\u0026#34;/sketches/trees/3dbrush.js\u0026#34; lib1=\u0026#34;https://cdn.jsdelivr.net/gh/VisualComputing/p5.treegl/p5.treegl.js\u0026#34; lib2=\u0026#34;https://cdn.jsdelivr.net/gh/freshfork/p5.EasyCam@1.2.1/p5.easycam.js\u0026#34; width=\u0026#34;625\u0026#34; height=\u0026#34;475\u0026#34; \u0026gt;    3d Brush js // Goal in the 3d Brush is double, to implement: // 1. a gesture parser to deal with depth, i.e., // replace the depth slider with something really // meaningful. You may use a 3d sensor hardware // such as: https://en.wikipedia.org/wiki/Leap_Motion // or machine learning software to parse hand (or // body) gestures from a (video) / image, such as: // https://ml5js.org/ // 2. other brushes to stylize the 3d brush, taking // into account its shape and alpha channel, gesture // speed, etc.  // Brush controls let color; let depth; let brush;  let easycam; let state;  let escorzo; let points; let record;  function setup() {  createCanvas(600, 450, WEBGL);  // easycam stuff  let state = {  distance: 250, // scalar  center: [0, 0, 0], // vector  rotation: [0, 0, 0, 1], // quaternion  };  easycam = createEasyCam();  easycam.state_reset = state; // state to use on reset (double-click/tap)  easycam.setState(state, 2000); // now animate to that state  escorzo = true;  perspective();   // brush stuff  points = [];  depth = createSlider(0, 1, 0.05, 0.05);  depth.position(10, 10);  depth.style(\u0026#39;width\u0026#39;, \u0026#39;580px\u0026#39;);  color = createColorPicker(\u0026#39;#ed225d\u0026#39;);  color.position(width - 70, 40);  // select initial brush  brush = sphereBrush; }  function draw() {  update();  background(120);  push();  strokeWeight(0.8);  stroke(\u0026#39;magenta\u0026#39;);  grid({ dotted: false });  pop();  axes();  for (const point of points) {  push();  translate(point.worldPosition);  brush(point);  pop();  } }  function update() {  let dx = abs(mouseX - pmouseX);  let dy = abs(mouseY - pmouseY);  speed = constrain((dx + dy) / (2 * (width - height)), 0, 1);  if (record) {  points.push({  worldPosition: treeLocation([mouseX, mouseY, depth.value()], { from: \u0026#39;SCREEN\u0026#39;, to: \u0026#39;WORLD\u0026#39; }),  color: color.color(),  speed: speed  });  } }  function sphereBrush(point) {  push();  noStroke();  // TODO parameterize sphere radius and / or  // alpha channel according to gesture speed  fill(point.color);  sphere(1);  pop(); }  function keyPressed() {  if (key === \u0026#39;r\u0026#39;) {  record = !record;  }  if (key === \u0026#39;p\u0026#39;) {  escorzo = !escorzo;  escorzo ? perspective() : ortho();  }  if (key == \u0026#39;c\u0026#39;) {  points = [];  } }  function mouseWheel(event) {  //comment to enable page scrolling  return false; }            // Goal in the 3d Brush is double, to implement: // 1. a gesture parser to deal with depth, i.e., // replace the depth slider with something really // meaningful. You may use a 3d sensor hardware // such as: https://en.wikipedia.org/wiki/Leap_Motion // or machine learning software to parse hand (or // body) gestures from a (video) / image, such as: // https://ml5js.org/ // 2. other brushes to stylize the 3d brush, taking // into account its shape and alpha channel, gesture // speed, etc. // Brush controls let color; let depth; let brush; let easycam; let state; let escorzo; let points; let record; function setup() { createCanvas(600, 450, WEBGL); // easycam stuff let state = { distance: 250, // scalar center: [0, 0, 0], // vector rotation: [0, 0, 0, 1], // quaternion }; easycam = createEasyCam(); easycam.state_reset = state; // state to use on reset (double-click/tap) easycam.setState(state, 2000); // now animate to that state escorzo = true; perspective(); // brush stuff points = []; depth = createSlider(0, 1, 0.05, 0.05); depth.position(10, 10); depth.style(\u0026#39;width\u0026#39;, \u0026#39;580px\u0026#39;); color = createColorPicker(\u0026#39;#ed225d\u0026#39;); color.position(width - 70, 40); // select initial brush brush = sphereBrush; } function draw() { update(); background(120); push(); strokeWeight(0.8); stroke(\u0026#39;magenta\u0026#39;); grid({ dotted: false }); pop(); axes(); for (const point of points) { push(); translate(point.worldPosition); brush(point); pop(); } } function update() { let dx = abs(mouseX - pmouseX); let dy = abs(mouseY - pmouseY); speed = constrain((dx \u0026#43; dy) / (2 * (width - height)), 0, 1); if (record) { points.push({ worldPosition: treeLocation([mouseX, mouseY, depth.value()], { from: \u0026#39;SCREEN\u0026#39;, to: \u0026#39;WORLD\u0026#39; }), color: color.color(), speed: speed }); } } function sphereBrush(point) { push(); noStroke(); // TODO parameterize sphere radius and / or // alpha channel according to gesture speed fill(point.color); sphere(1); pop(); } function keyPressed() { if (key === \u0026#39;r\u0026#39;) { record = !record; } if (key === \u0026#39;p\u0026#39;) { escorzo = !escorzo; escorzo ? perspective() : ortho(); } if (key == \u0026#39;c\u0026#39;) { points = []; } } function mouseWheel(event) { //comment to enable page scrolling return false; }      \"  "}]